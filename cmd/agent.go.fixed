package cmd

import (
	"bufio"
	"fmt"
	"io"
	"os"
	"strings"

	"github.com/spf13/cobra"
	"github.com/chzyer/readline"
)

func newAgentCmd() *cobra.Command {
	var model string
	var provider string
	var workingDir string
	var sessionID string
	var showProgress bool
	var maxSteps int
	var verbose bool

	cmd := &cobra.Command{
		Use:   "agent",
		Short: "Lightweight AI agent (console ‚Üí Slack/Telegram compatible)",
		Long: `Zen Agent - Lightweight AI agent with automatic tool chaining.

Designed for multi-client sessions:
- Start in console, continue in Slack/Telegram
- Minimal footprint: Agent only does tool execution
- Session-based: Save session ID to continue later
- No baked-in presentation logic

Architecture:
  Agent (tool execution) ‚Üê Session (conversation state)
       ‚Üë
  Clients (Console, Slack, Telegram, HTTP)

Examples:
  # Start a new session
  zen-claw agent "analyze project"
  
  # Start interactive mode (no arguments)
  zen-claw agent
  
  # Start with session ID (save for continuing)
  zen-claw agent --session-id my-task "check codebase"
  
  # Run with verbose output for debugging
  zen-claw agent --verbose "debug this issue"
  
  # Switch models during session:
  # Type "/models" to see available models
  # Type "/model qwen/qwen3-coder-30b-a3b-instruct" to switch to Qwen
  
  # Continue session from another client (future):
  # Use same session ID in Slack/Telegram bot`,
		Args: cobra.MaximumNArgs(1),
		Run: func(cmd *cobra.Command, args []string) {
			task := ""
			if len(args) > 0 {
				task = args[0]
			}
			runAgent(task, model, provider, workingDir, sessionID, showProgress, maxSteps, verbose)
		},
	}

	cmd.Flags().StringVar(&model, "model", "", "AI model (e.g., deepseek-chat)")
	cmd.Flags().StringVar(&provider, "provider", "", "AI provider (deepseek, openai, glm, minimax, qwen)")
	cmd.Flags().StringVar(&workingDir, "working-dir", ".", "Working directory for tools")
	cmd.Flags().StringVar(&sessionID, "session-id", "", "Session ID (for continuing sessions)")
	cmd.Flags().BoolVar(&showProgress, "progress", false, "Show progress in console (CLI only)")
	cmd.Flags().IntVar(&maxSteps, "max-steps", 50, "Maximum tool execution steps")
	cmd.Flags().BoolVar(&verbose, "verbose", false, "Enable verbose output for debugging")

	return cmd
}

func runAgent(task, modelFlag, providerFlag, workingDir, sessionID string, showProgress bool, maxSteps int, verbose bool) {
	// Interactive mode if no task provided
	if task == "" {
		runInteractiveMode(modelFlag, providerFlag, workingDir, sessionID, showProgress, maxSteps, verbose)
		return
	}

	if verbose {
		fmt.Println("üîß Verbose mode enabled")
	}

	if showProgress {
		fmt.Println("üöÄ Zen Agent - Gateway Client")
	} else {
		fmt.Println("üöÄ Zen Agent - Gateway Client")
	}
	fmt.Println("‚ïê" + strings.Repeat("‚ïê", 78))
	fmt.Printf("Task: %s\n", task)
	if sessionID != "" {
		fmt.Printf("Session ID: %s (save for continuing in Slack/Telegram)\n", sessionID)
	}
	fmt.Printf("Working directory: %s\n", workingDir)

	// Create gateway client
	client := NewGatewayClient("http://localhost:8080")

	// Check if gateway is running
	if err := client.HealthCheck(); err != nil {
		fmt.Printf("\n‚ùå Gateway not available: %v\n", err)
		fmt.Println("   Start the gateway first: zen-claw gateway start")
		os.Exit(1)
	}

	if verbose {
		fmt.Println("‚úì Gateway is healthy")
	}

	// Determine provider and model - in runAgent function
	providerName := providerFlag
	modelName := modelFlag

	// If model is specified but provider isn't, try to infer provider from model
	if modelName != "" && providerName == "" {
		providerName = inferProviderFromModel(modelName)
	}

	// If provider still not determined, use default
	if providerName == "" {
		providerName = "deepseek" // Default
	}

	// If model not specified, use default for provider
	if modelName == "" {
		// Default models per provider
		switch providerName {
		case "deepseek":
			modelName = "deepseek-chat"
		case "qwen":
			modelName = "qwen3-coder-30b-a3b-instruct"
		case "glm":
			modelName = "glm-4.7"
		case "minimax":
			modelName = "minimax-M2.1"
		case "openai":
			modelName = "gpt-4o-mini"
		default:
			modelName = "deepseek-chat"
		}
	}

	fmt.Printf("Provider: %s, Model: %s\n", providerName, modelName)
	if showProgress {
		fmt.Println()
	}

	// Prepare request
	req := ChatRequest{
		SessionID:  sessionID,
		UserInput:  task,
		WorkingDir: workingDir,
		Provider:   providerName,
		Model:      modelName,
		MaxSteps:   maxSteps,
	}

	if showProgress {
		fmt.Println("ü§ñ Sending request to gateway...")
		fmt.Println()
		fmt.Printf("üì° Gateway: http://localhost:8080\n")
		if sessionID != "" {
			fmt.Printf("   Session ID: %s\n", sessionID)
		}
		fmt.Printf("   Task: %s\n", task)
		fmt.Println()
	}

	// Send request to gateway
	resp, err := client.Send(req)
	if err != nil {
		fmt.Printf("\n‚ùå Gateway request failed: %v\n", err)
		os.Exit(1)
	}

	// Check for error in response
	if resp.Error != "" {
		fmt.Printf("\n‚ùå Agent execution failed: %s\n", resp.Error)
		os.Exit(1)
	}

	// Print result
	fmt.Println("\n" + strings.Repeat("‚ïê", 80))
	fmt.Println("üéØ RESULT (via Gateway)")
	fmt.Println(strings.Repeat("‚ïê", 80))
	fmt.Println(resp.Result)
	fmt.Println(strings.Repeat("‚ïê", 80))

	// Print session info from gateway response
	if sessionInfo := resp.SessionInfo; sessionInfo != nil {
		fmt.Printf("\nüìä Session Information:\n")
		if sid, ok := sessionInfo["session_id"].(string); ok {
			fmt.Printf("   Session ID: %s\n", sid)
		}
		if msgCount, ok := sessionInfo["message_count"].(float64); ok {
			fmt.Printf("   Messages: %.0f total\n", msgCount)
		}
		if userMsgs, ok := sessionInfo["user_messages"].(float64); ok {
			fmt.Printf("     - User: %.0f\n", userMsgs)
		}
		if assistantMsgs, ok := sessionInfo["assistant_messages"].(float64); ok {
			fmt.Printf("     - Assistant: %.0f\n", assistantMsgs)
		}
		if toolMsgs, ok := sessionInfo["tool_messages"].(float64); ok {
			fmt.Printf("     - Tool: %.0f\n", toolMsgs)
		}
		if wd, ok := sessionInfo["working_dir"].(string); ok {
			fmt.Printf("   Working directory: %s\n", wd)
		}
	}

	if showProgress {
		fmt.Printf("\nüí° To continue this session:\n")
		fmt.Printf("   zen-claw agent --session-id %s \"your next task\"\n", resp.SessionID)
	}
}

			MaxSteps:   maxSteps,
		}

		// Send request to gateway
		resp, err := client.Send(req)
		if err != nil {
			fmt.Printf("‚ùå Error: %v\n", err)
			continue
		}

		// Check for error in response
		if resp.Error != "" {
			fmt.Printf("‚ùå Agent error: %s\n", resp.Error)
			continue
		}

		// Print result
		fmt.Println("\n" + strings.Repeat("‚ïê", 80))
		fmt.Println("üéØ RESULT")
		fmt.Println(strings.Repeat("‚ïê", 80))
		fmt.Println(resp.Result)
		fmt.Println(strings.Repeat("‚ïê", 80))

		// Update session ID for continuation
		sessionID = resp.SessionID
	}
}

// inferProviderFromModel tries to infer provider from model name
func inferProviderFromModel(modelName string) string {
	modelName = strings.ToLower(modelName)

	// Check for provider patterns in model name
	if strings.Contains(modelName, "qwen") {
		return "qwen"
	} else if strings.Contains(modelName, "deepseek") {
		return "deepseek"
	} else if strings.Contains(modelName, "glm") {
		return "glm"
	} else if strings.Contains(modelName, "minimax") || strings.Contains(modelName, "abab") {
		return "minimax"
	} else if strings.Contains(modelName, "gpt") {
		return "openai"
	}

	// Could not infer provider
	return ""
}

// isModelCompatibleWithProvider checks if a model is likely compatible with a provider
func isModelCompatibleWithProvider(modelName, provider string) bool {
	modelName = strings.ToLower(modelName)
	provider = strings.ToLower(provider)

	switch provider {
	case "qwen":
		return strings.Contains(modelName, "qwen")
	case "deepseek":
		return strings.Contains(modelName, "deepseek")
	case "glm":
		return strings.Contains(modelName, "glm")
	case "minimax":
		return strings.Contains(modelName, "minimax") || strings.Contains(modelName, "abab")
	case "openai":
		return strings.Contains(modelName, "gpt")
	}

	// Unknown provider, assume compatible

